all.flux = all.flux[order(all.flux$farm), ]
all.flux$subp = c(1:3)
all.flux = all.flux[order(all.flux$farm, all.flux$subp), ]
all.flux$year =  rep(year, each = 664)
all.flux = all.flux[order(all.flux$farm, all.flux$year, all.flux$subp), ]
all.flux$dates = rep(dates, each = 4)
all.flux = all.flux[order(all.flux$farm, all.flux$year, all.flux$dates, all.flux$subp), ]
all.flux$reps = reps
all.flux = all.flux[order(all.flux$farm, all.flux$year, all.flux$reps, all.flux$subp), ]
all.flux$site = ifelse(all.flux$reps < 3, 1, 2)
#create unique IDs for merging all.flux and flux.calc
flux.calc$id = paste(flux.calc$farm, flux.calc$year, flux.calc$dates, flux.calc$site, flux.calc$reps, flux.calc$subp)
all.flux$id = paste(all.flux$farm, all.flux$year, all.flux$dates, all.flux$site, all.flux$reps, all.flux$subp)
#merge tables together
all.calc = merge(all.flux, flux.calc, by.x = "id", by.y = "id", all.x = T, all.y = T)
#gap fill missing data with linear interpolation
#make sure data are in plot by date order
all.calc = all.calc[order(all.calc$farm.x, all.calc$reps.x, all.calc$subp.x, all.calc$year.x, all.calc$dates.x), ]
#make ID field for grouping interpolations
all.calc$int = paste(all.calc$farm.x, all.calc$reps.x, all.calc$subp.x, all.calc$year.x)
#use na.approx inside mutate to interpolate within plots
#make all.calc a data table
all.calc.1 = data.table(all.calc)
#use na.approx within mutate to do the interpolation
all.calc.2 = data.table(all.calc %>%
group_by(int) %>%
mutate(cflux_int =  na.approx(finco, na.rm=FALSE), nflux_int = na.approx(posno, na.rm = F)))
#scale to 24 h and convert units to get kg ha d-1
all.calc.2$cint_d = (all.calc.2$cflux_int * 24) * (1 / 1e6) * (1e5 / 1)
all.calc.2$nint_d = (all.calc.2$nflux_int * 24) * (1 / 1e6) * (1e5 / 1)
#add values within sites and determine the number of days within each sum to scale total seasonal fluxes
all.calc.3 = all.calc.2[ , list(totc = sum(cint_d, na.rm = T), lenc = length(cint_d[!is.na(cint_d)]),
totn = sum(nint_d, na.rm = T), lenn = length(nint_d[!is.na(nint_d)])), by = int]
#median number of fluxes for N2O is 128 days. So all fluxes will be scaled to that
all.calc.3$totc_cor = all.calc.3$totc * 128 / all.calc.3$lenc
all.calc.3$totn_cor = all.calc.3$totn * 128 / all.calc.3$lenn
#separate id column
sps <- data.frame(do.call(rbind, str_split(all.calc.3$int, " ")))
names(sps) <- c("farm", "reps", "subp", "year")
#add id column to data frame
all.calc.4 = cbind(sps, all.calc.3)
#add column for management
all.calc.4$mgmt = ifelse(all.calc.4$reps == 1 | all.calc.4$reps == 2, "G", "H")
#convert to t / ha / y
all.calc.4$totc_g = all.calc.4$totc_cor / 1000
all.calc.4$totn_g = all.calc.4$totn_cor / 1000
View(all.calc.4)
all.calc.4dt$id3 = paste(all.calc.4dt$farm, all.calc.4dt$year, all.calc.4dt$mgmt, sep = " ")
all.calc.4dt = data.table(all.calc.4)
all.calc.4dt$id3 = paste(all.calc.4dt$farm, all.calc.4dt$year, all.calc.4dt$mgmt, sep = " ")
sitab3 = all.calc.4dt[ , list(mtotc_g = mean(totc_g, na.rm = T), lototc_g = quantile(totc_g, 0.025, na.rm = T),
hitotc_g = quantile(totc_g, 0.975, na.rm = T),
mtotn_g = mean(totn_g, na.rm = T), lototn_g = quantile(totn_g, 0.025, na.rm = T),
hitotn_g = quantile(totn_g, 0.975, na.rm = T)), by = id3]
#separate out just the mean values and rename
sitab3.mn = sitab3[ , c("id3", "mtotc_g", "mtotn_g")]
names(sitab3.mn) = c("id3", "totc_g", "totn_g")
#separate out lower quartile
sitab3.lo = sitab3[ , c("id3", "lototc_g", "lototn_g")]
names(sitab3.lo) = c("id3", "totc_g", "totn_g")
#separate out upper quartile
sitab3.hi = sitab3[ , c("id3", "hitotc_g", "hitotn_g")]
names(sitab3.hi) = c("id3", "totc_g", "totn_g")
#melt tables and add column names
sitab3.mnmel = melt(sitab3.mn, id.vars = "id3")
names(sitab3.mnmel) = c("id3", "var", "avg")
sitab3.lomel = melt(sitab3.lo, id.vars = "id3")
names(sitab3.lomel) = c("id3", "var", "lo")
sitab3.himel = melt(sitab3.hi, id.vars = "id3")
names(sitab3.himel) = c("id3", "var", "hi")
#round avg, lo, and hi values to two sig. digs.
sitab3.mnmel$avg = round(sitab3.mnmel$avg, 2)
sitab3.lomel$lo = round(sitab3.lomel$lo, 2)
sitab3.himel$hi = round(sitab3.himel$hi, 2)
#make new id column that contains Farm, Management, and var
sitab3.mnmel$id = paste(sitab3.mnmel$id3, sitab3.mnmel$var, sep = " ")
sitab3.lomel$id = paste(sitab3.lomel$id3, sitab3.lomel$var, sep = " ")
sitab3.himel$id = paste(sitab3.himel$id3, sitab3.himel$var, sep = " ")
#remove id3 and year columns
sitab3.mnmel = sitab3.mnmel[ , -c(1:2)]
sitab3.lomel = sitab3.lomel[ , -c(1:2)]
sitab3.himel = sitab3.himel[ , -c(1:2)]
#merge tables together
sitab3.1 = merge(sitab3.mnmel, sitab3.lomel, by.x = "id", by.y = "id")
sitab3.2 = merge(sitab3.1, sitab3.himel, by.x = "id", by.y = "id")
#make new column that contains the mean +- the upper and lower quartiles
sitab3.2$all = paste(sitab3.2$avg, " (", sitab3.2$lo, ", ", sitab3.2$hi, ")", sep = "")
#split the id string
sps <- data.frame(do.call(rbind, str_split(sitab3.2$id, " ")))
names(sps) <- c("farm", "year", "mgmt", "var")
#add to dataframe
sitab3.3 = cbind(sps, sitab3.2)
#remove columns for id, avg, lo, and hi
sitab3.3 = sitab3.3[ , -c(5:8)]
#select rows that are just FRF Graze
sitab3.4 = sitab3.3[sitab3.3$farm == "1" & sitab3.3$mgmt == "1", ]
names(sitab3.4) = c("farm", "year", "mgmt", "var", "FRF Graze")
#add columns for 1 2, etc.
sitab3.5 = cbind(sitab3.4, "FRF Hay" = sitab3.3[sitab3.3$farm == "1" & sitab3.3$mgmt == "2",]$all,
"ORG Graze" = sitab3.3[sitab3.3$farm == "2" & sitab3.3$mgmt == "1",]$all,
"ORG Hay" = sitab3.3[sitab3.3$farm == "2" & sitab3.3$mgmt == "2",]$all,
"WNF Graze" = sitab3.3[sitab3.3$farm == "3" & sitab3.3$mgmt == "1",]$all,
"WNF Hay" = sitab3.3[sitab3.3$farm == "3" & sitab3.3$mgmt == "2",]$all)
#export table
sitab3.5
sitab3.3
#separate out just the mean values and rename
sitab3.mn = sitab3[ , c("id3", "mtotc_g", "mtotn_g")]
names(sitab3.mn) = c("id3", "totc_g", "totn_g")
#separate out lower quartile
sitab3.lo = sitab3[ , c("id3", "lototc_g", "lototn_g")]
names(sitab3.lo) = c("id3", "totc_g", "totn_g")
#separate out upper quartile
sitab3.hi = sitab3[ , c("id3", "hitotc_g", "hitotn_g")]
names(sitab3.hi) = c("id3", "totc_g", "totn_g")
#melt tables and add column names
sitab3.mnmel = melt(sitab3.mn, id.vars = "id3")
names(sitab3.mnmel) = c("id3", "var", "avg")
sitab3.lomel = melt(sitab3.lo, id.vars = "id3")
names(sitab3.lomel) = c("id3", "var", "lo")
sitab3.himel = melt(sitab3.hi, id.vars = "id3")
names(sitab3.himel) = c("id3", "var", "hi")
#round avg, lo, and hi values to two sig. digs.
sitab3.mnmel$avg = round(sitab3.mnmel$avg, 2)
sitab3.lomel$lo = round(sitab3.lomel$lo, 2)
sitab3.himel$hi = round(sitab3.himel$hi, 2)
#make new id column that contains Farm, Management, and var
sitab3.mnmel$id = paste(sitab3.mnmel$id3, sitab3.mnmel$var, sep = " ")
sitab3.lomel$id = paste(sitab3.lomel$id3, sitab3.lomel$var, sep = " ")
sitab3.himel$id = paste(sitab3.himel$id3, sitab3.himel$var, sep = " ")
#remove id3 and year columns
sitab3.mnmel = sitab3.mnmel[ , -c(1:2)]
sitab3.lomel = sitab3.lomel[ , -c(1:2)]
sitab3.himel = sitab3.himel[ , -c(1:2)]
#merge tables together
sitab3.1 = merge(sitab3.mnmel, sitab3.lomel, by.x = "id", by.y = "id")
sitab3.2 = merge(sitab3.1, sitab3.himel, by.x = "id", by.y = "id")
#make new column that contains the mean +- the upper and lower quartiles
sitab3.2$all = paste(sitab3.2$avg, " (", sitab3.2$lo, ", ", sitab3.2$hi, ")", sep = "")
#split the id string
sps <- data.frame(do.call(rbind, str_split(sitab3.2$id, " ")))
names(sps) <- c("farm", "year", "mgmt", "var")
#add to dataframe
sitab3.3 = cbind(sps, sitab3.2)
sitab3.3
#remove columns for id, avg, lo, and hi
sitab3.3 = sitab3.3[ , -c("avg", "lo", "hi")]
str(sitab3.3)
#remove columns for id, avg, lo, and hi
sitab3.3 = sitab3.3[ , -c(5:8)]
sitab3.3
#select rows that are just FRF Graze
sitab3.4 = sitab3.3[sitab3.3$farm == "1" & sitab3.3$mgmt == "G", ]
names(sitab3.4) = c("farm", "year", "mgmt", "var", "FRF Graze")
sitab3.4
#add columns for 1 2, etc.
sitab3.5 = cbind(sitab3.4, "FRF Hay" = sitab3.3[sitab3.3$farm == "1" & sitab3.3$mgmt == "H",]$all,
"ORG Graze" = sitab3.3[sitab3.3$farm == "2" & sitab3.3$mgmt == "G",]$all,
"ORG Hay" = sitab3.3[sitab3.3$farm == "2" & sitab3.3$mgmt == "H",]$all,
"WNF Graze" = sitab3.3[sitab3.3$farm == "3" & sitab3.3$mgmt == "G",]$all,
"WNF Hay" = sitab3.3[sitab3.3$farm == "3" & sitab3.3$mgmt == "H",]$all)
sitab3.5
setwd("C:\\Users\\alix\\Box Sync\\UNH\\Projects\\USDA_ORG\\R Projects\\All-Farm-Tradeoffs\\Organic-Dairy\\Data")
write.table(sitab3.5, "SI_Table_3.csv", col.names = T, row.names = F, sep = ",")
View(bio.3)
names(bio.3)
bio.3dt$id3 = paste(bio.3dt$Farm, bio.3dt$Trt, sep = " ")
bio.3dt = data.table(bio.3)
bio.3dt$id3 = paste(bio.3dt$Farm, bio.3dt$Trt, sep = " ")
sitab4 = bio.3dt[ , list(mcsum = mean(csum, na.rm = T), locsum = quantile(csum, 0.025, na.rm = T),
hicsum = quantile(csum, 0.975, na.rm = T)), by = id3]
#separate out just the mean values and rename
sitab4.mn = sitab4[ , c("id3", "mcsum")]
names(sitab4.mn) = c("id3", "csum")
#separate out lower quartile
sitab4.lo = sitab4[ , c("id3", "locsum")]
names(sitab4.lo) = c("id3", "csum")
#separate out upper quartile
sitab4.hi = sitab4[ , c("id3", "hicsum")]
names(sitab4.hi) = c("id3", "csum")
#melt tables and add column names
sitab4.mnmel = melt(sitab4.mn, id.vars = "id3")
names(sitab4.mnmel) = c("id3", "var", "avg")
sitab4.lomel = melt(sitab4.lo, id.vars = "id3")
names(sitab4.lomel) = c("id3", "var", "lo")
sitab4.himel = melt(sitab4.hi, id.vars = "id3")
names(sitab4.himel) = c("id3", "var", "hi")
#round avg, lo, and hi values to two sig. digs.
sitab4.mnmel$avg = round(sitab4.mnmel$avg, 2)
sitab4.lomel$lo = round(sitab4.lomel$lo, 2)
sitab4.himel$hi = round(sitab4.himel$hi, 2)
#make new id column that contains Farm, Management, and var
sitab4.mnmel$id = paste(sitab4.mnmel$id3, sitab4.mnmel$var, sep = " ")
sitab4.lomel$id = paste(sitab4.lomel$id3, sitab4.lomel$var, sep = " ")
sitab4.himel$id = paste(sitab4.himel$id3, sitab4.himel$var, sep = " ")
#remove id3 and year columns
sitab4.mnmel = sitab4.mnmel[ , -c(1:2)]
sitab4.lomel = sitab4.lomel[ , -c(1:2)]
sitab4.himel = sitab4.himel[ , -c(1:2)]
#merge tables together
sitab4.1 = merge(sitab4.mnmel, sitab4.lomel, by.x = "id", by.y = "id")
sitab4.2 = merge(sitab4.1, sitab4.himel, by.x = "id", by.y = "id")
#make new column that contains the mean +- the upper and lower quartiles
sitab4.2$all = paste(sitab4.2$avg, " (", sitab4.2$lo, ", ", sitab4.2$hi, ")", sep = "")
#split the id string
sps <- data.frame(do.call(rbind, str_split(sitab4.2$id, " ")))
names(sps) <- c("farm", "mgmt", "var")
sitab4.2
#add to dataframe
sitab4.3 = cbind(sps, sitab4.2)
sitab4.3
#remove columns for id, avg, lo, and hi
sitab4.3 = sitab4.3[ , -c(4:7)]
sitab4.3
#select rows that are just FRF Graze
sitab4.4 = sitab4.3[sitab4.3$farm == "FRF" & sitab4.3$mgmt == "Graze", ]
names(sitab4.4) = c("farm", "year", "mgmt", "var", "FRF Graze")
names(sitab4.4) = c("farm", "mgmt", "var", "FRF Graze")
sitab4.4
#add columns for FRF Hay, etc.
sitab4.5 = cbind(sitab4.4, "FRF Hay" = sitab4.3[sitab4.3$farm == "FRF" & sitab4.3$mgmt == "Hay",]$all,
"ORG Graze" = sitab4.3[sitab4.3$farm == "ORG" & sitab4.3$mgmt == "Graze",]$all,
"ORG Hay" = sitab4.3[sitab4.3$farm == "ORG" & sitab4.3$mgmt == "Hay",]$all,
"WNF Graze" = sitab4.3[sitab4.3$farm == "WNF" & sitab4.3$mgmt == "Graze",]$all,
"WNF Hay" = sitab4.3[sitab4.3$farm == "WNF" & sitab4.3$mgmt == "Hay",]$all)
sitab4.5
setwd("C:\\Users\\alix\\Box Sync\\UNH\\Projects\\USDA_ORG\\R Projects\\All-Farm-Tradeoffs\\Organic-Dairy\\Data")
write.table(sitab4.5, "SI_Table_4.csv", col.names = T, row.names = F, sep = ",")
#set working directory
setwd("C:\\Users\\alix\\Box Sync\\UNH\\Projects\\EPSCoR_Sensor\\Data\\CO2_Flux\\HUB\\QA_1\\")
# this loop takes all the processed files and combines them into one master file
#calls the files in the specified directory
files = dir("C:\\Users\\alix\\Box Sync\\UNH\\Projects\\EPSCoR_Sensor\\Data\\CO2_Flux\\HUB\\QA_1\\")
#create matrix with one row and same column names as calculated flux files.  This for the loop to have a place for pasting
#files it reads in
#ncol = 32 for line power sites; 38 for non-line power
HUB.all <- data.frame(matrix(data=NA, nrow=1, ncol=38, byrow=FALSE, dimnames=list("1", c("Year", "Month", "DayOfMonth", "Hour",
"Minute", "Second", "DayOfYr", "FracDayOfYr", "Flag_FracDayOfYr", "CHBR_NUM", "cell_press", "Flag_cell_press",
"SiteAirTemp", "Flag_SiteAirTemp", "ChamberTemp", "Flag_ChamberTemp", "SoilTemp1_Chamber", "Flag_SoilTemp1_Chamber",
"SoilTemp2_Chamber", "Flag_SoilTemp2_Chamber", "SoilTemp3_Chamber", "Flag_SoilTemp3_Chamber", "VWC1_Chamber",
"Flag_VWC1_Chamber", "VWC2_Chamber", "Flag_VWC2_Chamber", "VWC3_Chamber", "Flag_VWC3_Chamber",
#for solar sites
"BattBank1Volt", "Flag_BattBank1Volt", "BattBank2Volt", "Flag_BattBank2Volt", "CompPress", "Flag_CompPress",
"CO2_Flux_1", "Flag_flux_stage1", "CO2_Flux_2", "Flag_flux_stage2"))))
# start the loop to go through the whole directory
for (i in seq(length(files))) {
# identify the names of the file to be processed
filename = paste("C:\\Users\\alix\\Box Sync\\UNH\\Projects\\EPSCoR_Sensor\\Data\\CO2_Flux\\HUB\\QA_1\\",
files[i], sep = '')
# add to the HUB.all matrix by just combining the next file under the existing HUBa
HUB.all = rbind(HUB.all, read.table(filename, header = TRUE, sep = ','))
}
#examine number of records for each year-month combo.  QA for adjusting any operator errors in changing code when calculating fluxes
table(HUB.all$Year, HUB.all$Month)
#create YrFracDayOfYr column for HUBa sorting
HUB.all$YrFracDayOfYr <- as.numeric(ifelse(HUB.all$FracDayOfYr < 10, paste(HUB.all$Year, 0, 0, HUB.all$FracDayOfYr, sep = ""),
ifelse(HUB.all$FracDayOfYr < 100, paste(HUB.all$Year, 0, HUB.all$FracDayOfYr, sep = ""),
paste(HUB.all$Year, HUB.all$FracDayOfYr, sep = ""))))
#create posix compliant time object for plotting across multiple sites
HUB.all$TS <- paste(HUB.all$Year, "-", HUB.all$Month, "-", HUB.all$DayOfMonth, " ", HUB.all$Hour, ":", HUB.all$Minute, sep = "")
HUB.all$TIMESTAMP <- as.POSIXct(strptime(HUB.all$TS, "%Y-%m-%d %H:%M", tz="EST"))
#sort data by YrFracDayOfYr
HUB.all <- HUB.all[order(HUB.all$YrFracDayOfYr), ]
#create an ID field for merging with empty data frame
HUB.all$id <- paste(HUB.all$Year, HUB.all$DayOfYr, HUB.all$Hour, HUB.all$Minute, sep = " ")
################################################################################
#remove fluxes outside sampling window (specified in log) plus unrealistic values before March 30 and after November 30
quantile(HUB.all$CO2_Flux_2, na.rm = TRUE, probs = c(80, 90, 95, 98, 99, 99.5, 99.9, 100)/100)
#spurious value is 2X the 99% quantile
HUB.all$CO2_Flux_3 <- ifelse(HUB.all$CO2_Flux_2 == 0, NA,
ifelse(HUB.all$Year == 2014 & HUB.all$DayOfYr < 128, NA,
ifelse(HUB.all$Year == 2014 & HUB.all$DayOfYr > 288, NA,
ifelse(HUB.all$Year == 2015 & HUB.all$DayOfYr < 131, NA,
ifelse(HUB.all$Year == 2015 & HUB.all$DayOfYr > 336, NA,
ifelse(HUB.all$Year == 2016 & HUB.all$DayOfYr < 90, NA,
ifelse(HUB.all$Year == 2016 & HUB.all$DayOfYr > 306, NA,
ifelse(HUB.all$Year == 2017 & HUB.all$DayOfYr < 187, NA,
ifelse(HUB.all$Year == 2017 & HUB.all$DayOfYr > 319, NA,
ifelse(HUB.all$Year == 2018 & HUB.all$DayOfYr < 137, NA,
ifelse(HUB.all$Year == 2018 & HUB.all$DayOfYr > 295, NA,
ifelse(HUB.all$DayOfYr > 90 & HUB.all$DayOfYr < 335 & HUB.all$CO2_Flux_2 > 20.84475, NA,
HUB.all$CO2_Flux_2))))))))))))
#flag values that are oustide range
HUB.all$Flag_flux_stage3 = ifelse(is.na(HUB.all$CO2_Flux_2) == T, HUB.all$Flag_flux_stage2,
ifelse(is.na(HUB.all$CO2_Flux_3) == T, "AR", "P"))
#create vector that encompasses what should be the entire time series that does not have data gaps
#first create vectors for DOY, hour, minute
ts.Year <- seq(2013, 2017)
ts.DOY <- seq(91, 335)
ts.hour <- seq(0, 23)
ts.min <- 2
#then create an empty data frame and populate it with DOY, hour, minute, second, FracDOY, and CHBR_NUM
samp.frame <- data.frame(matrix(data = NA, nrow = length(ts.Year) * length(ts.DOY) * length(ts.hour) * length(ts.min), ncol = 4))
names(samp.frame) <- c("Year", "DOY", "hour", "min")
samp.frame$Year <- rep(ts.Year, nrow(samp.frame)/length(ts.Year))
samp.frame <- samp.frame[order(samp.frame$Year), ]
samp.frame$DOY <- rep(ts.DOY, nrow(samp.frame)/length(ts.DOY))
samp.frame <- samp.frame[order(samp.frame$DOY), ]
samp.frame$hour <- rep(ts.hour, nrow(samp.frame)/(length(ts.hour) * length(ts.min)))
samp.frame <- samp.frame[order(samp.frame$hour), ]
samp.frame$min <- rep(ts.min, nrow(samp.frame)/length(ts.min))
samp.frame$ts.id <- paste(samp.frame$Year, samp.frame$DOY, samp.frame$hour, samp.frame$min, sep = " ")
#merge with bdf.all
hub.sf <- merge(samp.frame, HUB.all, by.x = "ts.id", by.y = "id", all.x = TRUE, all.y = FALSE)
#make CO2_Flux_3 a ts object for gap filling
hub.sf$CO2_Flux_3 <- ts(hub.sf$CO2_Flux_3)
##sort data by YrFracDayOfYr
hub.sf <- hub.sf[order(hub.sf$YrFracDayOfYr), ]
#fill NA values with na.approx, with the max gap that cal be filled as < 1 day, or 24 fluxes
hub.sf$nee.int <- ifelse(is.na(hub.sf$CO2_Flux_3) == T, na.approx(hub.sf$CO2_Flux_3, na.rm = FALSE, maxgap = 24), hub.sf$CO2_Flux_3)
#flag values as interpolated where appropriate
hub.sf$Flag_int = ifelse(is.na(hub.sf$CO2_Flux_3) == T & is.na(hub.sf$nee.int) == F, "IN",
ifelse(is.na(hub.sf$CO2_Flux_3) == T & is.na(hub.sf$nee.int) == T, "M", "P"))
View(hub.sf)
#set working directory
setwd("C:\\Users\\alix\\Box Sync\\UNH\\Projects\\EPSCoR_Sensor\\Data\\CO2_Flux\\HUB\\")
write.table(hub.sf, "Hubbard_Brook_CO2_Fluxes.csv", col.names = T, row.names = F)
write.table(hub.sf, "Hubbard_Brook_CO2_Fluxes.csv", sep = ",", col.names = T, row.names = F)
table(hub.sf$Flag_int)
setwd("C:\\Users\\alix\\Box Sync\\UNH\\Projects\\USDA_ORG\\Soils Data")
allold = read.table("All_Soils_Data.csv", head = T, sep = ",")
cold = read.table("old_carb.csv", head = T, sep = ",")
cnew = read.table("new_carb.csv", head = T, sep = ",")
plocs = read.table("ODRF_Time_Series_Soils.txt", head = T, sep = ",")
#merge cold and cnew
del = merge(cnew, cold, by.x = "Sample_ID", by.y = "Sample_ID", all.x = T, all.y = T)
names(del)
hist(del$oldC)
hist(del$oldN)
hist(del$oldCN)
hist(del$Clay)
3*3*4*2
1.6 * 2
125 * 3
100 *12
#call libraries
library(data.table)
library(splitstackshape)
library(zoo)
library(matrixStats)
library(MASS)
library(stringr)
library(dunn.test)
library(plyr)
library(nlme)
library(multcomp)
#set directories and import files
setwd("C:\\Users\\alix\\Box Sync\\UNH\\Projects\\USDA_ORG\\Soils Data")
allold = read.table("All_Soils_Data.csv", head = T, sep = ",")
cold = read.table("old_carb.csv", head = T, sep = ",")
cnew = read.table("new_carb.csv", head = T, sep = ",")
plocs = read.table("ODRF_Time_Series_Soils.txt", head = T, sep = ",")
View(plocs)
View(cold)
View(del)
#merge cold and cnew
del = merge(cnew, cold, by.x = "Sample_ID", by.y = "Sample_ID", all.x = T, all.y = T)
View(del)
#split the Plot ID string in plocs
ptids <- data.frame(do.call(rbind, str_split(plocs$PlotID, c("East", "West"))))
View(ptids)
#split the Plot ID string in plocs
ptids <- data.frame(do.call(rbind, str_split(plocs$PlotID, c("East"))))
plocs$E = gsub("West", "W")
gsub("West", "W", plocs)
plocs1 = gsub("West", "W", plocs)
View(plocs1)
plocs
gsub("West", "W", plocs$PlotID)
plocs = gsub("East", "E", plocs$PlotID)
View(plocs)plocs
View(plocs)
plocs = read.table("ODRF_Time_Series_Soils.txt", head = T, sep = ",")
plocs$PlotID = gsub("West", "W", plocs$PlotID)
View(plocs)
plocs = gsub("East", "E", plocs$PlotID)
plocs = read.table("ODRF_Time_Series_Soils.txt", head = T, sep = ",")
#merge cold and cnew
del = merge(cnew, cold, by.x = "Sample_ID", by.y = "Sample_ID", all.x = T, all.y = T)
plocs$PlotID = gsub("West", "W", plocs$PlotID)
plocs$PlotID = gsub("East", "E", plocs$PlotID)
View(plocs)
#split the new PlotID field in plocs
sps <- data.frame(do.call(rbind, str_split(plocs$PlotID, "E")))
View(sps)
#split the new PlotID field in plocs
sps <- data.frame(do.call(rbind, str_split(plocs$PlotID, "")))
#split the new PlotID field in plocs
sps <- data.frame(do.call(rbind, str_split(plocs$PlotID, "E")))
View(sps)
#split the new PlotID field in plocs
esps <- data.frame(do.call(rbind, str_split(plocs$PlotID, "E")))
wsps <- data.frame(do.call(rbind, str_split(plocs$PlotID, "W")))
View(esps)
View(wsps)
View(esps)
#create new vector with Plot_ID in the same format as Sample_ID in del
PlotID = ifelse(is.integer(esps$X2) == T, paste(esps$X2, "E", sep = ""),
ifelse(is.integer(wsps$X2) == T), paste(wsps$X2), "W", sep = "")), NA)
#create new vector with Plot_ID in the same format as Sample_ID in del
PlotID = ifelse(is.integer(esps$X2) == T, paste(esps$X2, "E", sep = ""),
ifelse(is.integer(wsps$X2) == T), paste(wsps$X2, "W", sep = ""), NA)
#create new vector with Plot_ID in the same format as Sample_ID in del
PlotID = ifelse(is.integer(esps$X2) == T, paste(esps$X2, "E", sep = ""),
ifelse(is.integer(wsps$X2) == T, paste(wsps$X2, "W", sep = ""), NA))
View(PlotID)
is.integer(esps$X2) == T
is.integer(esps$X2)[1] == T
is.integer(esps$X2)[2] == T
length(esps$X2)
nchar(esps$X2)
plocs = read.table("ODRF_Time_Series_Soils.txt", head = T, sep = ",")
View(plocs)
plocs = read.table("ODRF_Time_Series_Soils.csv", head = T, sep = ",")
View(plocs)
#merge del with plocs
dlocs = merge(plocs, del, by.x = "Sample_ID", by.y = "Sample_ID")
view(dlocs)
View(dlocs)
#merge del with plocs and format as data table
dlocs = data.table(merge(plocs, del, by.x = "Sample_ID", by.y = "Sample_ID"))
table(dlocs$MUSYM)
#first splot the MUSYM string so that it is differentiated by series
dlocs$mu = data.frame(do.call(rbind, str_split(dlocs$MUKEY, "")[[3]]))
#first splot the MUSYM string so that it is differentiated by series
dlocs$mu = data.frame(do.call(rbind, str_split(dlocs$MUKEY, "")[[1]]))
#first splot the MUSYM string so that it is differentiated by series
dlocs$mu = data.frame(do.call(rbind, str_split(dlocs$MUKEY, "")))
View(dlocs)
#first splot the MUSYM string so that it is differentiated by series
mu = data.frame(do.call(rbind, str_split(dlocs$MUKEY, "")[[3]]))
#first splot the MUSYM string so that it is differentiated by series
mu = data.frame(do.call(rbind, str_split(dlocs$MUKEY, "")[[1]]))
#first splot the MUSYM string so that it is differentiated by series
mu = data.frame(do.call(rbind, str_split(dlocs$MUKEY, "")))
mu
#first splot the MUSYM string so that it is differentiated by series
mu = data.frame(do.call(rbind, str_split(dlocs$MUSYM, "")))
mu
dlocs$mu = paste(mu$X1, mu$X2)
dlocs$mu = paste(mu$X1, mu$X2, sep = "")
boxplot(cold ~ mu, data = dlocs)
boxplot(oldC ~ mu, data = dlocs)
boxplot(oldC ~ Field_ID, data = dlocs)
boxplot(oldC ~ mu * Field_ID, data = dlocs)
boxplot(oldC ~ mu, data = dlocs)
#create column for mu by field
dlocs$muf = paste(dlocs$Field_ID, dlocs$mu)
#create new column for fields that fit within naming scheme
dlocs$trt = ifelse(dlocs$Field_ID == 1, "H3",
ifelse(dlocs$Field_ID == 5, "H4",
ifelse(dlocs$Field_ID == 2, "G1",
ifelse(dlocs$Field_ID == 3, "G2", NA))))
#create column for mu by field
dlocs$muf = paste(dlocs$trt, dlocs$mu)
table(dlocs$muf)
#create new column for fields that fit within naming scheme
dlocs$trt = ifelse(dlocs$Field_ID == 1, "H3",
ifelse(dlocs$Field_ID == 5, "H4",
ifelse(dlocs$Field_ID == 2, "G1",
ifelse(dlocs$Field_ID == 4, "G2", NA))))
table(dlocs$muf)
dlocs = dlocs[complete.cases(dlocs$trt), ]
#create column for mu by field
dlocs$muf = paste(dlocs$trt, dlocs$mu)
table(dlocs$muf)
#calculate median value by field and map unit
cmuf = dlocs[, list(Field.ID = unique(trt), mu = unique(mu),
carb_2.5 = quantile(oldC / 100, 0.025, na.rm = T)), by = muf]
cmuf
#calculate median value by field and map unit
cmuf = dlocs[, list(Field.ID = unique(trt), mu = unique(mu),
carb_2.5 = quantile(oldC / 100, 0.025, na.rm = T),
carb_25 = quantile(oldC / 100, 0.25, na.rm = T),
carb_50 = quantile(oldC / 100, 0.5, na.rm = T),
carb_75 = quantile(oldC / 100, 0.75, na.rm = T),
carb_97.5 = quantile(oldC / 100, 0.975, na.rm = T),
Clay_2.5 = quantile(Clay / 100, 0.025, na.rm = T),
Clay_25 = quantile(Clay / 100, 0.25, na.rm = T),
Clay_50 = quantile(Clay / 100, 0.5, na.rm = T),
Clay_75 = quantile(Clay / 100, 0.75, na.rm = T),
Clay_97.5 = quantile(Clay / 100, 0.975, na.rm = T)),
by = muf]
cmuf
#calculate median value by field and map unit
cmuf = dlocs[, list(Field.ID = unique(trt), mu = unique(mu),
carb_2.5 = quantile(oldC / 100, 0.025, na.rm = T),
carb_25 = quantile(oldC / 100, 0.25, na.rm = T),
carb_50 = quantile(oldC / 100, 0.5, na.rm = T),
carb_75 = quantile(oldC / 100, 0.75, na.rm = T),
carb_97.5 = quantile(oldC / 100, 0.975, na.rm = T),
Clay_2.5 = quantile(Clay / 100, 0.025, na.rm = T),
Clay_25 = quantile(Clay / 100, 0.25, na.rm = T),
Clay_50 = quantile(Clay / 100, 0.5, na.rm = T),
Clay_75 = quantile(Clay / 100, 0.75, na.rm = T),
Clay_97.5 = quantile(Clay / 100, 0.975, na.rm = T)), by = muf]
cmuf
View(cmuf)
write.table(cmuf, "carb_clay_mu_field.csv", row.names = F, col.names = T, sep = ",")
33285 + 6275
84 * 2
168 * 0.575
168 * 0.575 * 8
176 + 61
237 * 4
237 * 4 * 8
7584 + 772.8
125 * 3
9 / 12
108 + 60 + (27 * 12)
(108 * 12) + (60 * 12) + (27 * 12)
(9 * 12) + (5 * 12) + (27 * 12)
